{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['50 pesos', '100 pesos', '200 pesos', '500 pesos', '1000 pesos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Ideas for Objects to Detect\n",
    "raw_frames_type_1 = [ ]\n",
    "raw_frames_type_2 = [ ]\n",
    "raw_frames_type_3 = [ ]\n",
    "raw_frames_type_4 = [ ]\n",
    "raw_frames_type_5 = [ ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ideas for Objects to Detect\n",
    "#     1. Bag\n",
    "#     2. Ballpoint\n",
    "#     3. Paper\n",
    "#     4. Pencil\n",
    "#     5. Watter Bottle\n",
    "\n",
    "# Money Bills Denominations\n",
    "#  2. 50 pesos\n",
    "#  3. 100 pesos\n",
    "#  4. 200 pesos\n",
    "#  5. 500 pesos\n",
    "#  6. 1000 pesos\n",
    "\n",
    "# creating realtime dataset\n",
    "\n",
    "CAMERA = cv2.VideoCapture(0)\n",
    "camera_height = 500\n",
    "\n",
    "while CAMERA.isOpened():\n",
    "    #read a new camera frame\n",
    "\n",
    "    ret, frame = CAMERA.read()\n",
    "\n",
    "    #Flip\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    #Rescale the images output\n",
    "\n",
    "    aspect = frame.shape[1]/float (frame.shape[0])\n",
    "    res = int(aspect * camera_height)\n",
    "    frame = cv2.resize(frame, (res, camera_height))\n",
    "\n",
    "    #the green rectangle frame\n",
    "    cv2.rectangle(frame, (300, 75), (650, 425), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow (\"Capturing\", frame)\n",
    "\n",
    "    #controls q = quit / s = capturing\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key & 0xff == ord ('q'):\n",
    "        break\n",
    "    elif key & 0xff == ord ('1'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_1.append(frame)\n",
    "    elif key & 0xff == ord ('2'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_2.append(frame)\n",
    "    elif key & 0xff == ord ('3'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_3.append(frame)\n",
    "    elif key & 0xff == ord ('4'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_4.append(frame)\n",
    "    elif key & 0xff == ord ('5'):\n",
    "        #save the raw frames to frame\n",
    "        raw_frames_type_5.append(frame)\n",
    "\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n",
    "    \n",
    "CAMERA.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera\n",
    "save_width = 339\n",
    "save_height = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Module Call\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "retval = os.getcwd()\n",
    "print (\"Currently Working Directory %s\" % retval)\n",
    "\n",
    "#Creating Folders\n",
    "if not os.path.exists('img_1'):\n",
    "    for i in range(1,len(class_names)+1):\n",
    "        os.makedirs('img_{}/'.format(i))\n",
    "\n",
    "\n",
    "print ('img1:', len(raw_frames_type_1))\n",
    "print ('img2:', len(raw_frames_type_2))\n",
    "print ('img3:', len(raw_frames_type_3))\n",
    "print ('img4:', len(raw_frames_type_4))\n",
    "print ('img5:', len(raw_frames_type_5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop the images\n",
    "\n",
    "#for frames type 1\n",
    "for i, frame in enumerate (raw_frames_type_1):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_1/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#for frames type 2\n",
    "for i, frame in enumerate (raw_frames_type_2):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_2/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#for frames type 3\n",
    "for i, frame in enumerate (raw_frames_type_3):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_3/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#for frames type 4\n",
    "for i, frame in enumerate (raw_frames_type_4):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_4/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "for i, frame in enumerate (raw_frames_type_5):\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    #parse BRG to RGB\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    #resize to 224 x 224\n",
    "    roi = cv2.resize(roi, (save_width, save_height))\n",
    "    #save \n",
    "    cv2.imwrite ('img_5/{}.png'.format(i), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# from keras import preprocessing\n",
    "# import keras.utils as image\n",
    "# import tensorflow.keras.preprocessing\n",
    "from keras.utils import load_img, img_to_array, array_to_img\n",
    "\n",
    "width = 96\n",
    "height = 96\n",
    "\n",
    "images_type_1 = [ ]\n",
    "images_type_2 = [ ]\n",
    "images_type_3 = [ ]\n",
    "images_type_4 = [ ]\n",
    "images_type_5 = [ ]\n",
    "\n",
    "for image_path in glob('img_1/*.*'):\n",
    "    image = load_img(image_path, target_size = (width, height))\n",
    "    x = img_to_array(image)\n",
    "\n",
    "    images_type_1.append(x)\n",
    "    \n",
    "for image_path in glob('img_2/*.*'):\n",
    "    image = load_img(image_path, target_size = (width, height))\n",
    "    x = img_to_array(image)\n",
    "\n",
    "    images_type_2.append(x)\n",
    "    \n",
    "for image_path in glob('img_3/*.*'):\n",
    "    image = load_img(image_path, target_size = (width, height))\n",
    "    x = img_to_array(image)\n",
    "\n",
    "    images_type_3.append(x)\n",
    "    \n",
    "for image_path in glob('img_4/*.*'):\n",
    "    image = load_img(image_path, target_size = (width, height))\n",
    "    x = img_to_array(image)\n",
    "\n",
    "    images_type_4.append(x)\n",
    "\n",
    "for image_path in glob('img_5/*.*'):\n",
    "    image = load_img(image_path, target_size = (width, height))\n",
    "    x = img_to_array(image)\n",
    "\n",
    "    images_type_5.append(x)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, x in enumerate(images_type_1[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[0]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, x in enumerate(images_type_2[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[1]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, x in enumerate(images_type_3[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[2]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, x in enumerate(images_type_4[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[3]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, x in enumerate(images_type_5[:5]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    image = array_to_img(x)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('{} image'.format(class_names[4]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prepare image to tensor\n",
    "\n",
    "X_type_1 = np.array(images_type_1)\n",
    "X_type_2 = np.array(images_type_2)\n",
    "X_type_3 = np.array(images_type_3)\n",
    "X_type_4 = np.array(images_type_4)\n",
    "X_type_5 = np.array(images_type_5)\n",
    "\n",
    "#check the shape using .shape() check the images count\n",
    "\n",
    "print (X_type_1.shape)\n",
    "print (X_type_2.shape)\n",
    "print (X_type_3.shape)\n",
    "print (X_type_4.shape)\n",
    "print (X_type_5.shape)\n",
    "\n",
    "\n",
    "# (13, 96, 96, 3)\n",
    "# (23, 96, 96, 3)\n",
    "# (14, 96, 96, 3)\n",
    "# (22, 96, 96, 3)\n",
    "\n",
    "# X_type_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_type_1, X_type_2), axis= 0)\n",
    "\n",
    "if len(X_type_3):\n",
    "    X = np.concatenate((X, X_type_3), axis= 0)\n",
    "if len (X_type_4):\n",
    "    X = np.concatenate((X, X_type_4), axis= 0)\n",
    "if len (X_type_5):\n",
    "    X = np.concatenate((X, X_type_5), axis= 0)\n",
    "\n",
    "X = X / 250.0\n",
    "\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_type_1 = [0 for item in enumerate(X_type_1)]\n",
    "y_type_2 = [1 for item in enumerate(X_type_2)]\n",
    "y_type_3 = [2 for item in enumerate(X_type_3)]\n",
    "y_type_4 = [3 for item in enumerate(X_type_4)]\n",
    "y_type_5 = [4 for item in enumerate(X_type_5)]\n",
    "\n",
    "y = np.concatenate((y_type_1, y_type_2), axis= 0)\n",
    "\n",
    "if len(y_type_3):\n",
    "    y = np.concatenate((y, y_type_3), axis= 0)\n",
    "if len(y_type_4):\n",
    "    y = np.concatenate((y, y_type_4), axis= 0)\n",
    "if len(y_type_5):\n",
    "    y = np.concatenate((y, y_type_5), axis= 0)\n",
    "\n",
    "y = to_categorical(y, num_classes=len(class_names))\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN config\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#default parameters\n",
    "\n",
    "#situational - values, you may not adjust here\n",
    "\n",
    "conv_1 = 16\n",
    "conv_1_drop = 0.2\n",
    "conv_2 = 32\n",
    "conv_2_drop = 0.2\n",
    "dense_1_n = 1024\n",
    "dense_1_drop = 0.2\n",
    "dense_2_n = 512\n",
    "dense_2_drop = 0.2\n",
    "\n",
    "#values you can adjust\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "color_channels = 3\n",
    "\n",
    "\n",
    "def build_model(conv_1_drop = conv_1_drop, conv_2_drop =conv_2_drop,\n",
    "                dense_1_n = dense_1_n, dense_1_drop = dense_1_drop,\n",
    "                dense_2_n = dense_2_n, dense_2_drop = dense_2_drop, lr = lr):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(conv_1, (3,3),\n",
    "                            input_shape = (width, height,color_channels),\n",
    "                            activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(conv_1_drop))\n",
    "    \n",
    "    #---\n",
    "    model.add(Convolution2D(conv_2, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(conv_2_drop)) #Changed \n",
    "\n",
    "    #---\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #---\n",
    "    model.add(Dense(dense_1_n, activation='relu'))\n",
    "    model.add(Dropout(dense_1_drop))\n",
    "\n",
    "    #---\n",
    "    model.add(Dense(dense_2_n, activation= 'relu'))\n",
    "    model.add(Dropout(dense_2_drop))\n",
    "\n",
    "    #---\n",
    "    model.add(Dense(len(class_names), activation= 'softmax'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                optimizer= Adam(clipvalue = 0.5),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#model parameter\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not run yet\n",
    "\n",
    "history = model.fit(X, y, validation_split = 0.10, epochs = 10, batch_size = 5)\n",
    "\n",
    "print (history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %.2f%%' % (scores[1]*100))\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Loss and Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plt_show(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# class_names = ['BAG', 'BALLPOINT', 'PAPER', 'PENCIL', 'WATER BOTTLE']\n",
    "\n",
    "_50_bills = 'img_1/10.png'\n",
    "_100_bills = 'img_2/10.png'\n",
    "_200_bills= 'img_3/10.png'\n",
    "_500_bills = 'img_4/10.png'\n",
    "_1000_bills = 'img_5/10.png'\n",
    "\n",
    "imgs = [_50_bills, _100_bills, _200_bills, _500_bills, _1000_bills]\n",
    "\n",
    "classes = None\n",
    "predicted_classes = [ ]\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    type_ = load_img(imgs[i], target_size=(width, height))\n",
    "    plt.imshow(type_)\n",
    "    plt.show()\n",
    "\n",
    "    type_x = np.expand_dims(type_, axis=0)\n",
    "    prediction = model.predict(type_x)\n",
    "    index = np.argmax(prediction)\n",
    "    print(class_names[index])\n",
    "    classes = class_names[index]\n",
    "    predicted_classes.append(class_names[index])\n",
    "\n",
    "cm = confusion_matrix(class_names, predicted_classes)\n",
    "f = sns.heatmap(cm, xticklabels=class_names, yticklabels=predicted_classes, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_1 = load_img(imgs[0], target_size=(width, height)) \n",
    "\n",
    "plt.imshow(type_1)\n",
    "plt.show()\n",
    "\n",
    "type_1_x = np.expand_dims(type_1, axis=0)\n",
    "prediction = model.predict(type_1_x)\n",
    "index = np.argmax(prediction)\n",
    "\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_2 = load_img(imgs[1], target_size=(width, height)) #Need further checking\n",
    "\n",
    "plt.imshow(type_2)\n",
    "plt.show()\n",
    "\n",
    "type_2_x = np.expand_dims(type_2, axis=0)\n",
    "prediction = model.predict(type_2_x)                \n",
    "index = np.argmax(prediction)\n",
    "\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_3 = load_img(imgs[2], target_size=(width, height)) #Need further checking\n",
    "\n",
    "plt.imshow(type_3)\n",
    "plt.show()\n",
    "\n",
    "type_3_x = np.expand_dims(type_3, axis=0)\n",
    "prediction = model.predict(type_3_x)\n",
    "\n",
    "index = np.argmax(prediction)\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_4 = load_img(imgs[3], target_size=(width, height)) #Need further checking\n",
    "\n",
    "plt.imshow(type_4)\n",
    "plt.show()\n",
    "\n",
    "type_4_x = np.expand_dims(type_4, axis=0)\n",
    "prediction = model.predict(type_4_x)\n",
    "\n",
    "index = np.argmax(prediction)\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_5 = load_img(imgs[4], target_size=(width, height)) #Need further checking\n",
    "\n",
    "plt.imshow(type_5)\n",
    "plt.show()\n",
    "\n",
    "type_5_x = np.expand_dims(type_5, axis=0)\n",
    "prediction = model.predict(type_5_x)\n",
    "\n",
    "index = np.argmax(prediction)\n",
    "print(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live predicion using camera\n",
    "\n",
    "from keras.applications import inception_v3\n",
    "\n",
    "import time\n",
    "\n",
    "CAMERA = cv2.VideoCapture(0)\n",
    "camera_height  = 500\n",
    "\n",
    "while (True):\n",
    "    _, frame = CAMERA.read()\n",
    "\n",
    "    #flip \n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    #rescale the image output\n",
    "    aspect = frame.shape[1] / float (frame.shape [0])\n",
    "    res = int (aspect* camera_height)\n",
    "    frame = cv2.resize(frame, (res, camera_height))\n",
    "\n",
    "    #get roi\n",
    "    roi = frame[75+2:425-2, 300+2:650-2]\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Adjust Alignment \n",
    "    roi = cv2.resize(roi, (width, height))\n",
    "    roi_x = np.expand_dims(roi, axis = 0)\n",
    "\n",
    "    predictions = model.predict(roi_x)\n",
    "\n",
    "    type_1_x, type_2_x, type_3_x, type_4_x, type_5_x = predictions[0]\n",
    "    # type_1_x, type_2_x, type_3_x, type_4_x = predictions\n",
    "\n",
    "    #The green rectable \n",
    "    cv2.rectangle(frame, (300,75), (650,425), (240, 100, 0), 2)\n",
    "\n",
    "    #Predictions/Labels\n",
    "    tipe_1_txt ='{} - {}%'.format(class_names[0], int(type_1_x*100))\n",
    "    cv2.putText(frame, tipe_1_txt, (70,210), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "    tipe_2_txt ='{} - {}%'.format(class_names[1], int(type_2_x*100))\n",
    "    cv2.putText(frame, tipe_2_txt, (70,235), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "    tipe_3_txt ='{} - {}%'.format(class_names[2], int(type_3_x*100))\n",
    "    cv2.putText(frame, tipe_3_txt, (70,255), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "    tipe_4_txt ='{} - {}%'.format(class_names[3], int(type_4_x*100))\n",
    "    cv2.putText(frame, tipe_4_txt, (70,275), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "    tipe_5_txt ='{} - {}%'.format(class_names[4], int(type_5_x*100))\n",
    "    cv2.putText(frame, tipe_5_txt, (70,275), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (240,240,240), 2)\n",
    "\n",
    "    cv2.imshow(\"Real time object detection\", cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    #Controls q = quit/s = capturing \n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "    #preview\n",
    "    plt.imshow(frame)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camera\n",
    "CAMERA.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
